{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laaCqpI2S_hf"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q sentence_transformers\n",
        "!pip install -q umap\n",
        "!pip install -q umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJMCWXGPPrc3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import itertools\n",
        "from datasets import Dataset\n",
        "from scipy import stats\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "from sentence_transformers import models, SentenceTransformer, losses, evaluation, InputExample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QRKci_FKWAz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "import eval_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZVjQWzIG6hK"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc3Xa9wQiryX"
      },
      "outputs": [],
      "source": [
        "def make_cls_pairs_bin_similarity(df, bin_column, transcript_column):\n",
        "    train_examples = []\n",
        "    processed_pairs = set()\n",
        "    \n",
        "    for i, row in df.iterrows():\n",
        "        # Get sample\n",
        "        sample = row[transcript_column]\n",
        "        sample_task = row['task']\n",
        "        sample_bin = row[bin_column]\n",
        "        \n",
        "        # Get pairs within the same task\n",
        "        task_df = df[(df['task'] == sample_task) & (df[transcript_column] != sample)].copy()\n",
        "        \n",
        "        for j, pair_row in task_df.iterrows():\n",
        "            pair_sample = pair_row[transcript_column]\n",
        "            \n",
        "            # Check if the pair has already been processed\n",
        "            if (sample, pair_sample) in processed_pairs or (pair_sample, sample) in processed_pairs:\n",
        "                continue\n",
        "\n",
        "            pair_bin = pair_row[bin_column]\n",
        "            \n",
        "            # Calculate cosine similarity label based on bins\n",
        "            similarity_label = 1 if sample_bin == pair_bin else 0\n",
        "            \n",
        "            train_examples.append(InputExample(texts=[sample, pair_sample], label=similarity_label))\n",
        "\n",
        "            # Add the processed pair to the set\n",
        "            processed_pairs.add((sample, pair_sample))\n",
        "    \n",
        "    return train_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2kMUYj0OFeVz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/finnish_average.csv\")\n",
        "\n",
        "model_name = \"drive/MyDrive/FIN_TASK_MODELS_SIAM/epoch3_split{}\"\n",
        "\n",
        "criterion_column = 'task_completion_mean' #'ta_facets'\n",
        "bin_column = 'ta_bins' #'ta_bins_r'\n",
        "folder_name = \"FIN_TA_MODELS_SIAM_BIN_TASK\"\n",
        "\n",
        "results_df = pd.DataFrame()\n",
        "all_true = []\n",
        "all_samples = []\n",
        "\n",
        "for e in range(3):\n",
        "  print(\"epoch \"+str(e))\n",
        "  all_predictions = []\n",
        "  pred_before_training = []\n",
        "  for split in df['split'].unique():\n",
        "    print(\"----------------------------\")\n",
        "    print(\"split {}\".format(split))\n",
        "    \n",
        "    # make saving path\n",
        "    model_path = \"drive/MyDrive/\"+folder_name+\"/epoch{}_split{}\".format(e,split)\n",
        "    \n",
        "    train_df = df[df['split']!=split].reset_index(drop=True)\n",
        "    test_df = df[df['split']==split].reset_index(drop=True)\n",
        "    \n",
        "    if e == 0:\n",
        "      # add values to the df\n",
        "      split_true = test_df[criterion_column].tolist()\n",
        "      all_true+=split_true\n",
        "      \n",
        "      split_sample = test_df['sample'].tolist()\n",
        "      all_samples+=split_sample\n",
        "\n",
        "      # load untrained model\n",
        "      model = SentenceTransformer(model_name.format(split), device=device)\n",
        "\n",
        "      pre_emb_dict = eval_utils.get_embed_dict(df['clean_transcript'].unique().tolist(), model)\n",
        "      train_df['pre_training_embeds'] = [pre_emb_dict[sent] for sent in train_df['clean_transcript']]\n",
        "      test_df['pre_training_embeds'] = [pre_emb_dict[sent] for sent in test_df['clean_transcript']]\n",
        "\n",
        "          \n",
        "      y_pred_ta = eval_utils.get_bert_n_closest_score(train_df,\n",
        "                                                      test_df,\n",
        "                                                      \"pre_training_embeds\",\n",
        "                                                      criterion_column)\n",
        "      pred_before_training+=y_pred_ta\n",
        "      \n",
        "    else:\n",
        "      # load trained in previous epoch\n",
        "      pre_model_path = \"drive/MyDrive/\"+folder_name+\"/epoch{}_split{}\".format(e-1,split)\n",
        "      model = SentenceTransformer(pre_model_path, device=device)\n",
        "    \n",
        "    \n",
        "    emb_dict = eval_utils.get_embed_dict(train_df['clean_transcript'].unique().tolist(), model)\n",
        "    train_df['pre_training_embeds'] = [emb_dict[sent] for sent in train_df['clean_transcript']]\n",
        "    \n",
        "    train_examples = make_cls_pairs_bin_similarity(train_df, bin_column, \"clean_transcript\")\n",
        "    print(len(train_examples))\n",
        "    #random.shuffle(train_examples)\n",
        "    #train_examples = train_examples[:1500]\n",
        "\n",
        "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "\n",
        "    train_loss = losses.ContrastiveLoss(model=model)\n",
        "    \n",
        "    model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=0)\n",
        "    model.save(model_path)\n",
        "    \n",
        "    emb_dict = eval_utils.get_embed_dict(df['clean_transcript'].unique().tolist(), model.eval())\n",
        "    train_df['post_training_embeds'] = [emb_dict[sent] for sent in train_df['clean_transcript']]\n",
        "    test_df['post_training_embeds'] = [emb_dict[sent] for sent in test_df['clean_transcript']]\n",
        "    df['post_training_embeds'] = [emb_dict[sent] for sent in df['clean_transcript']]\n",
        "    \n",
        "    y_pred_ta = eval_utils.get_bert_n_closest_score(train_df,\n",
        "                                                    test_df,\n",
        "                                                    \"post_training_embeds\",\n",
        "                                                    criterion_column)\n",
        "\n",
        "    all_predictions+=y_pred_ta\n",
        "\n",
        "  \n",
        "  if e==0:\n",
        "    results_df['samples']=all_samples\n",
        "    results_df['true']=all_true\n",
        "    results_df['pre']=pred_before_training\n",
        "    results_df['epoch0']=all_predictions\n",
        "  else:\n",
        "    results_df['epoch'+str(e)]=all_predictions\n",
        "  \n",
        "  print(\"POST TRAINING 1NN\")\n",
        "  eval_utils.evaluate_cls(all_true, all_predictions)\n",
        "  print('----------')\n",
        "  eval_utils.evaluate_reg(all_true, all_predictions, \"sbert 1nn epoch {}\".format(e))\n",
        "  print('----------')\n",
        "  eval_utils.compute_task_scores(df, 'task','post_training_embeds')\n",
        "  print('----------')\n",
        "  eval_utils.compute_bin_scores(df, 'post_training_embeds', bin_column)\n",
        "  eval_utils.plot_n_random_tasks(df, 'task', 'post_training_embeds', n=10)\n",
        "  eval_utils.plot_subtask(df, 'task', 1, 'post_training_embeds', criterion_column)\n",
        "  #-----------------------------------------\n",
        "\n",
        "  results_df.to_csv(\"drive/MyDrive/\"+folder_name+\"/results_cls.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}